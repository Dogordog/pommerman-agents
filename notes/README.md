# pommerman-agents/notes

I am intending to incrementally implement the algorithms used in DeepMind's FTW Agents paper. The overall architecture incorporates several techniques that I am new to so I probably wouldn't be able to implement them fully but it will be a great lesson. Some of them also need to be adapted eg. pixel control can't be directly used since we are not using pixel inputs.

I will also find time to post material at [greentfrapp.github.io](https://greentfrapp.github.io).

## Reference Papers and Links

- Pommerman [website](https://www.pommerman.com/), [library](https://github.com/MultiAgentLearning/playground) and [documentation](https://github.com/MultiAgentLearning/playground/tree/master/docs)

- FTW Agents paper by Jaderberg et al. (2018) and [blog post](https://deepmind.com/blog/capture-the-flag/).

[Jaderberg, Max, et al. "Human-level performance in first-person multiplayer games with population-based deep reinforcement learning." arXiv preprint arXiv:1807.01281 (2018).](https://arxiv.org/abs/1807.01281)

- Population Based Training paper by Jaderberg et al. (2017).

[Jaderberg, Max, et al. "Population based training of neural networks." arXiv preprint arXiv:1711.09846 (2017).](https://arxiv.org/abs/1711.09846)

- Reinforced Variational Inference paper by Weber et al. (2015).

[Weber, Theophane, et al. "Reinforced variational inference." Advances in Neural Information Processing Systems (NIPS) Workshops. 2015.](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/viral.pdf)

- Auxiliary Tasks (Pixel Control) paper by Jaderberg et al. (2016) and [blog post](https://deepmind.com/blog/reinforcement-learning-unsupervised-auxiliary-tasks/).

[Jaderberg, Max, et al. "Reinforcement learning with unsupervised auxiliary tasks." arXiv preprint arXiv:1611.05397 (2016).](https://arxiv.org/abs/1611.05397)
